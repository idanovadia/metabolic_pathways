import pandas as pd
import numpy as np
from random import randint
import random
import networkx as nx
import os
import classifier.sub2vec.randonWalk as rw
import classifier.sub2vec.doc2vec as d2v
from classifier.code_tools.Abstract_config_class import AbstractConfigClass
import json
import time


class Sub2Vec(AbstractConfigClass):

    def __init__(self):
        AbstractConfigClass.__init__(self)

    '''
    randomWalk_threshold - number of nodes in each graph.
    random_walk_graphs_to_create - number of graphs to create of each sub graph.
    subGraphs_directory_path - directory path to sub graphs files (networks format).
    random_walk_directory_path_output - path to directory to save the new sub graphs that generated by Random Walk Algo.
    subGraphs_list - list of sub graphs input.
    rw_list_of_graphs_train - list of sub graphs that generated by Random Walk Algo.
    '''

    def setup(self):
        self.randomWalk_length = self.config_parser.eval(self.__class__.__name__, 'random_walk_length')
        self.sub2vecMethod = self.config_parser.eval(self.__class__.__name__, 'sub2vecMethod')
        self.random_walk_num = self.config_parser.eval(self.__class__.__name__,
                                                                    'random_walk_number')
        self.subGraphs_directory_path = self.getPath(
            relative_path=self.config_parser.eval(self.__class__.__name__, 'subGraphs_directory_path'))
        self.random_walk_directory_path_output = self.getPath(
            relative_path=self.config_parser.eval(self.__class__.__name__, 'random_walk_directory_path_output'))
        self.classifier_files_directory = self.getPath(
            relative_path=self.config_parser.eval(self.__class__.__name__, 'classifier_files_directory'))
        self.statistics_output_path=self.getPath(relative_path=self.config_parser.eval(self.__class__.__name__, 'statistics_output_path'))

        self.subGraphs_list = []
        self.rw_list_of_graphs_train = []
        self.rw_list_of_graphs_train_positive = []
        self.rw_list_of_graphs_train_negative = []
        self.rw_list_of_graphs_test = []

        self.rw_args = json.loads(self.config_parser.get(self.__class__.__name__, 'randomwalk_args'))
        self.rw_extensions = self.config_parser.eval(self.__class__.__name__, 'rw_extensions').split(",")
        self.doc2vec_args=json.loads(self.config_parser.get(self.__class__.__name__, 'doc2vec_args'))



    def exec(self):
        begin = time.time()
        self.generateSubGraphs()
        print("generateSubGraphs :" + str(time.time()-begin))
        begin = time.time()
        self.randomWalk()
        print("randomWalk :" + str(time.time()-begin))
        # self.chooseBestSubgraphs()
        # self.WriteAll()
        # self.statistics()
        begin = time.time()
        self.doc2vec()
        print("doc2vec :" + str(time.time()-begin))
        self.generateTrain()
        self.generateLabel("train_label.xlsx", self.rw_list_of_graphs_train)
        # self.generateTest()
        # self.generateLabel("test_label.xlsx",self.rw_list_of_graphs_test)

    '''Use directory path and read all the saved sab graphs there'''

    def generateSubGraphs(self):
        for filename in os.listdir(self.subGraphs_directory_path):
            try:
                self.subGraphs_list.append(
                    (filename, (nx.read_gml(os.path.join(self.subGraphs_directory_path, filename)))))
            except:
                continue

    '''Doing Random Walk on the sub graphs'''

    def randomWalk(self):
        self.main_graph = nx.read_gml(
            self.getPath(relative_path=self.config_parser.eval(self.__class__.__name__, 'main_graph_path')))
        random_walk_object = rw.RandomWalk(threshold=self.randomWalk_length,
                                           number_of_graphs=self.random_walk_num,args=self.rw_args,extensions=self.rw_extensions,main_graph=self.main_graph)
        for k in self.subGraphs_list:
            g = k[1]
            g.graph["name"] = k[0]
            if g.graph['type'] == "trainset":
                self.rw_list_of_graphs_train = random_walk_object.insertGraphToSet(
                    list_of_graphs=self.rw_list_of_graphs_train,
                    graph=g)
                # self.rw_list_of_graphs_train = random_walk_object.insertGraphToSet(
                #     list_of_graphs=self.rw_list_of_graphs_train,
                #     graph=random_walk_object.randomWalk(g))

            # else:
            #     for i in range(self.random_walk_graphs_to_create):
            #         self.rw_list_of_graphs_test = random_walk_object.insertGraphToSet(
            #             list_of_graphs=self.rw_list_of_graphs_test,
            #             graph=random_walk_object.randomWalk(g))

    def chooseBestSubgraphs(self):
        self.createLabeledList(self.rw_list_of_graphs_train_positive, "positive")
        self.createLabeledList(self.rw_list_of_graphs_train_negative, "negative")
        self.rw_list_of_graphs_train =[]
        self.bestPositives()
        self.bestNegatives()
        self.rw_list_of_graphs_train = self.rw_list_of_graphs_train_negative[:100] + self.rw_list_of_graphs_train_positive[:100]
        # self.rw_list_of_graphs_train = self.rw_list_of_graphs_train_negative[:len(self.rw_list_of_graphs_train_positive)] + self.rw_list_of_graphs_train_positive
        random.shuffle(self.rw_list_of_graphs_train)

    def bestPositives(self):
        self.rw_list_of_graphs_train_positive.sort(key=lambda x: (len(x.nodes), len(x.nodes)),reverse=True);

    def bestNegatives(self):
        self.rw_list_of_graphs_train_negative.sort(key=lambda x: (len(x.nodes), len(x.nodes)),reverse=True);


    def createLabeledList(self, labeledList, label):
        for i in self.rw_list_of_graphs_train:
            if i.graph["label"] == label:
                labeledList.append(i)

    '''Using Doc2vec to get embedding'''

    def doc2vec(self):
        doc2vec_obj_train = d2v.Doc2Vec(**self.doc2vec_args)
        doc2vec_obj_train.transform(self.rw_list_of_graphs_train,self.sub2vecMethod)
        self.vectors_train = doc2vec_obj_train.fit()
        # doc2vec_obj_test = d2v.Doc2Vec(self.rw_list_of_graphs_test)
        # self.vectors_test = doc2vec_obj_test.fit()

    '''Create train data'''

    def generateTrain(self):
        csv = pd.DataFrame(self.vectors_train.doctag_syn0)
        self.saveFile(csv, self.classifier_files_directory, "train.xlsx")

    '''Create test data'''

    def generateTest(self):
        csv = pd.DataFrame(self.vectors_test.doctag_syn0)
        self.saveFile(csv, self.classifier_files_directory, "test.xlsx")

    '''Create label data'''

    def generateLabel(self, file, list):
        labels = []
        [labels.append("positive") if (len(g)>0 and g[0].graph['label'] == "positive") else labels.append("negative") for g in list]
        csv = pd.DataFrame(labels)
        self.saveFile(csv, self.classifier_files_directory, file)

    '''
    save xls file to specific dir. 
    '''

    def saveFile(self, csv, path, name):
        csv.to_excel(os.path.join(path, name),index=False)

    ''' write all graphs to gml graph format'''

    def WriteAll(self):
        for id, graph in enumerate(self.rw_list_of_graphs_train):
            self.writeFile(graph)

    ''' write a graph to gml graph format'''

    def writeFile(self, G):
        nx.write_gml(G=G, path=os.path.join(self.random_walk_directory_path_output, G.name))
        # nx.write_gml(G=G, path=os.path.join(self.random_walk_directory_path_output, str(id) + ".gml"))

    def statistics(self):
        columns = ["correlation threshold","rw length","rw number of times","extensions", "Main Graph: number of nodes", "Main Graph: number of edges", "number of subgraphs",
                   "avg number of sentences per subgraph", "avg number of words per sentence", "doc2vec args"]
        correlation_treshold=self.config_parser.eval("GraphCreator", 'threshold')
        ext=self.getImprovments()
        number_of_nodes=len(self.main_graph.nodes())
        number_of_edges=self.main_graph.number_of_edges()
        avg_number_of_sentences_per_subgraph=self.avgSentencesPerGraph()
        avg_number_of_words_per_sentence=self.avgNumberOfWordsPerSentence()
        number_of_subgraphs=len(self.rw_list_of_graphs_train)

        if os.path.exists(self.statistics_output_path+os.sep+"statistics"+'.xlsx'):
            df=pd.read_excel(self.statistics_output_path+os.sep+"statistics"+'.xlsx',index=False)
        else :
            df=pd.DataFrame(columns=columns)
        df = df.append(pd.Series([correlation_treshold,self.randomWalk_length,self.random_walk_num,ext,
                                      number_of_nodes,
                                      number_of_edges,
                                      number_of_subgraphs,
                                      avg_number_of_sentences_per_subgraph,
                                      avg_number_of_words_per_sentence,
                                      self.doc2vec_args], index=df.columns), ignore_index=True)

        df.to_excel(self.statistics_output_path + os.sep+ "statistics" + ".xlsx", index=False)


    def avgSentencesPerGraph(self):
        return sum([len(subgraph) for subgraph in self.rw_list_of_graphs_train])/len(self.rw_list_of_graphs_train)

    def avgNumberOfWordsPerSentence(self):
        number_of_sentences=len([sentence for subgraph in self.rw_list_of_graphs_train for sentence in subgraph])
        number_of_words=0
        for subgraph in self.rw_list_of_graphs_train:
            for sentence in subgraph:
                number_of_words+=len(sentence.nodes())


        return number_of_words/number_of_sentences

    def getImprovments(self):
        extensions=[str(self.config_parser.eval('GraphCreator', 'adj_matrix_extensions')).replace('}','').replace('{','').replace(':','=').replace("'", ""),
                    self.config_parser.eval('GraphCreator','graph_extensions'),
                    str(self.config_parser.eval('Sub2Vec', 'rw_extensions'))
                    ]
        last=""
        result=""
        for extension in extensions:
            if last=="":
                result+=extension
            else:
                result+=','+extension
            last=extension
        return result




